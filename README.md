# MLworkshopTeh
## Mini Practical Lecture Series: Application of Machine Learning in Environmental Data üéì

 üìù**Aim:** This series aims to equip attendees with the necessary tools and environment to begin working with environmental data using Machine Learning (ML). The series will cover system setups, introduction to Git, Python environments and packaging, data handling, and foundational concepts of ML with practical examples in environmental contexts. 

**Material:** 
- Jupyter Notebooks
-  GitHub Repository ()

**Day 1: Setting up and Data Handling Basics **
- Laptop/System Setups: Guidelines for preparing a personal computer for ML work (Day1/00Setup.ipnyb)
- Introduction to Git & Version Control: Basics of using Git for code management (Dat1/01Git_python.ipynb)
- Python Environments: Setting up and managing Python environments for ML projects (Dat1/01Git_python.ipynb)
- Python Packaging: How to use and create Python packages (Day1/02Package.ipynb)
- Data Handling Basics (Day1/03Dataanalysis.ipnyb) üìä
   - Introduction to ``Pandas`` and ``NumPy`` for data manipulation,
   - Data visualization with ``Matplotlib`` and ``Seaborn``,
   -  Using ``SciPy`` and ``SymPy``.
 
**Day 2: Machine Learning Concepts and Environmental Applications **

- Basics & Concepts of Machine Learning: Understanding the core principles of ML, with a focus on classification and regression (Day2/03MLbasics.ipynb)
- Practical Examples:
   - Creating a Python-based classification model.
   - Developing a regression model in Python. 

- Environmental Case Studies: 

Predicting Earthquakes: Utilizing ML for seismic data analysis. 

Sediment Prediction via Well Log Data: Applying ML to geological datasets. 

Things that will impact your overall marks for each section are:
<p>‚úÖ How clean and easy to read your code is, and how well structured your notebook/your class is: this includes using markdown cells to explain your decisions if needed (don't justify all basic decisions though: the code needs to speak for itself)</p>
<p>‚úÖ The overall performance of your algorithm at two distinct metrics:<br>
<l>
<ul>1. Obtaining as small a difference as possible between the F1 predicted on your test set, and the F1 of your prediction on the unkown samples.</ul>
<ul>2. Using as few coefficients (`weights`) in your parametric model as possible, whilst maintaining a relatively high F1 score on your unseen data. This will be measured by the ratio of F1 / number of weights.</ul>
</l>
.</p>
<p>‚úÖ Whether or not you have demonstrated through code that your solution follows the best practices of data science.</p>
<br>


